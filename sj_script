git clone https://github.com/pubmedqa/pubmedqa.git

wget https://huggingface.co/bofenghuang/Meta-Llama-3-8B/resolve/1460c22666392e470910ce3d44ffeb2ab7dbd4df/original/tokenizer.model


python split_dataset.py pqal

; python3 llama/preprocess_pubmeqa.py --input_dir pubmedqa/data/train_data --output_file pubmedqa/pubmeqa_preprocessed.txt
python3 llama/preprocess_pubmeqa.py --input_dir pubmedqa/data --output_file  pubmedqa/pubmeqa_preprocessed.txt



python3 llama/training.py \
        --ckpt_dir Meta-Llama-3-8B-Instruct \
        --tokenizer_path Meta-Llama-3-8B-Instruct/tokenizer.model \
        --data_path pubmedqa/pubmeqa_preprocessed_train.txt \
        --output_dir checkpoint_dir/finetuned_pubmeqa \
        --batch_size 8

accelerate launch llama/training.py \
        --ckpt_dir Meta-Llama-3-8B-Instruct \
        --tokenizer_path Meta-Llama-3-8B-Instruct/tokenizer.model \
        --data_path pubmedqa/pubmeqa_preprocessed_train.txt \
        --output_dir checkpoint_dir/finetuned_pubmeqa \
        --batch_size 1

그리고 추론이 완성되었으면, 체크포인팅 된걸 복구해서 추론성능 테스트하는 코드 llama/inference.py 만들어줘. 
추론 데이터 셋은 json 파일로 pubmedqa/test_set.json꼴로 되어있어